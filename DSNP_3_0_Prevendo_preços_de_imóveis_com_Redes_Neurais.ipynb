{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasPequenoSterzeck/Data_Visualization/blob/main/DSNP_3_0_Prevendo_pre%C3%A7os_de_im%C3%B3veis_com_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cikxhCV7Zjo"
      },
      "source": [
        "<img alt=\"Colaboratory logo\" width=\"15%\" src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/novo_logo_bg_claro.png\">\n",
        "\n",
        "#### **Data Science na Prática 3.0**\n",
        "*by [sigmoidal.ai](https://sigmoidal.ai)*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqjlUbCzeUDi"
      },
      "source": [
        "# Prevendo preços de imóveis com Redes Neurais\n",
        "\n",
        "Para demonstrar como as redes neurais podem ser usadas para um problema de regressão, para prever preços de venda de imóveis, vou usar o conhecido *dataset* California housing.\n",
        "\n",
        "<center><img src=\"https://www.wartsila.com/images/default-source/default-album/california_housing.tmb-1920x690.jpg?sfvrsn=126bc44_1\" width=\"80%\"></center>\n",
        "\n",
        "\n",
        "\n",
        "A maneira que iremos construir a arquitetura de redes neurais é por meio da API `Sequential` do `keras`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kX1Axbt3fkqI"
      },
      "source": [
        "# importar as bibliotecas necessárias\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qz4Tspkz73sj"
      },
      "source": [
        "Uma vez importados todos os pacotes necessários, é hora de carregarmos os dados e começarmos o nosso projeto!\n",
        "\n",
        "Para isso, utilizaremos um dataset do próprio `sklearn.dataset`, o `California Housing`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2eTwcOQj1kr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a91d05-596f-465e-baa9-347303ffdc52"
      },
      "source": [
        "# baixar os dados\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "housing = fetch_california_housing()\n",
        "feature_names = housing['feature_names']\n",
        "feature_names.append('Target')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Cal. housing from https://ndownloader.figshare.com/files/5976036 to /root/scikit_learn_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqldZdYd9f4w"
      },
      "source": [
        "Além disso, precisamos transformar esse conjunto em um DataFrame dentro do Pandas.\n",
        "\n",
        "Podemos fazer isso com a sequência de código abaixo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMVSOw9d1k6Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "625cf3ca-6a03-4ba5-ca08-63e0555e655c"
      },
      "source": [
        "# converter dados em DataFrame\n",
        "df = pd.concat([pd.DataFrame(housing.data), pd.Series(housing.target)], axis=1)\n",
        "df.columns = feature_names\n",
        "\n",
        "# ver as 5 primeiras entradas\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "      <td>4.526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "      <td>3.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "      <td>3.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.422</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   MedInc  HouseAge  AveRooms  AveBedrms  ...  AveOccup  Latitude  Longitude  Target\n",
              "0  8.3252      41.0  6.984127   1.023810  ...  2.555556     37.88    -122.23   4.526\n",
              "1  8.3014      21.0  6.238137   0.971880  ...  2.109842     37.86    -122.22   3.585\n",
              "2  7.2574      52.0  8.288136   1.073446  ...  2.802260     37.85    -122.24   3.521\n",
              "3  5.6431      52.0  5.817352   1.073059  ...  2.547945     37.85    -122.25   3.413\n",
              "4  3.8462      52.0  6.281853   1.081081  ...  2.181467     37.85    -122.25   3.422\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0fMSLjdx9ouU"
      },
      "source": [
        "Agora sim estamos prontos para, de fato, fazer nossas previsões usando redes neurais.\n",
        "\n",
        "Abaixo, podemos ver o código completo, desde a separaç!ão dos dados até o resultado do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgNC-CYc7LZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e372a65-7f5a-45ef-e59e-d2d831ac81bb"
      },
      "source": [
        "# 1. escolher e importar um modelo\n",
        "# Rede Neural usando API SEQUENTIAL\n",
        "\n",
        "# 3. Separar os dados entre feature matrix e target vector\n",
        "X = df.drop('Target', axis=1)\n",
        "y = df['Target']\n",
        "\n",
        "# 3.1 Dividir o dataset entre treino e teste\n",
        "X_train_completo, X_test, y_train_completo, y_test = train_test_split(X, y)\n",
        "\n",
        "# 3.2 Dividir os dados de treino entre treino e validação\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_completo, y_train_completo)\n",
        "\n",
        "# 3.3 Padronizar os dados (MUITO importante para redes neurais)\n",
        "sc = StandardScaler().fit(X_train)\n",
        "X_train = sc.transform(X_train)\n",
        "X_valid = sc.transform(X_valid)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# 2. Instanciar e escolher os hyperparameters\n",
        "model = keras.models.Sequential()\n",
        "model.add(keras.layers.Dense(50, input_shape=(X_train.shape[1:]), activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='relu'))\n",
        "model.add(keras.layers.Dense(1))\n",
        "\n",
        "# 4. Fit do modelo (treinar)\n",
        "model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "history = model.fit(X_train, y_train, epochs=25, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# 5. Avaliar o modelo\n",
        "print(model.evaluate(X_test, y_test))\n",
        "\n",
        "# 5.1 Fazer previsões em cima de novos dados\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "363/363 [==============================] - 4s 4ms/step - loss: 0.7305 - val_loss: 2.4159\n",
            "Epoch 2/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.6263 - val_loss: 0.4338\n",
            "Epoch 3/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4186 - val_loss: 0.4502\n",
            "Epoch 4/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.4129 - val_loss: 0.5560\n",
            "Epoch 5/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3928 - val_loss: 0.3723\n",
            "Epoch 6/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3729 - val_loss: 0.3671\n",
            "Epoch 7/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3652 - val_loss: 0.3626\n",
            "Epoch 8/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3584 - val_loss: 0.3560\n",
            "Epoch 9/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3548 - val_loss: 0.3518\n",
            "Epoch 10/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3495 - val_loss: 0.3445\n",
            "Epoch 11/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3445 - val_loss: 0.3440\n",
            "Epoch 12/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3418 - val_loss: 0.3373\n",
            "Epoch 13/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3376 - val_loss: 0.3423\n",
            "Epoch 14/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3349 - val_loss: 0.3343\n",
            "Epoch 15/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3310 - val_loss: 0.3355\n",
            "Epoch 16/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3293 - val_loss: 0.3262\n",
            "Epoch 17/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3259 - val_loss: 0.3224\n",
            "Epoch 18/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3249 - val_loss: 0.3241\n",
            "Epoch 19/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3225 - val_loss: 0.3235\n",
            "Epoch 20/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3187 - val_loss: 0.3191\n",
            "Epoch 21/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3157 - val_loss: 0.3133\n",
            "Epoch 22/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3149 - val_loss: 0.3154\n",
            "Epoch 23/25\n",
            "363/363 [==============================] - 1s 4ms/step - loss: 0.3125 - val_loss: 0.3207\n",
            "Epoch 24/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3113 - val_loss: 0.3163\n",
            "Epoch 25/25\n",
            "363/363 [==============================] - 1s 3ms/step - loss: 0.3101 - val_loss: 0.3090\n",
            "162/162 [==============================] - 0s 2ms/step - loss: 0.3152\n",
            "0.31524384021759033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7NlJDy-FXyu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70cf2ab-68e6-4a69-ddfb-0a3fc1bdcc30"
      },
      "source": [
        "# ATENÇÃO para o shape do input\n",
        "print(X_train.shape[1])\n",
        "print(X_train.shape[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "(8,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HB_N53gIpCa"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}